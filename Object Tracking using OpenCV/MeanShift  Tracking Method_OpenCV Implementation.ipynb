{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meanshift Tracking Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanshift can be given a target to track, calculate the color histogram of the target area and then keep sliding the tracking window to the closest match (the cluster center).\n",
    "\n",
    "Note: Meanshift won't change the window size if the target moves away or towards the camera.\n",
    "we can use CamShift to update the size of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will start off by actually grabing the image from our camera..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# we will start by setting our initial tracking window...\n",
    "\n",
    "# Previously we were using corner detection to do this just detecting 10 best corners on the first frame and tracking\n",
    "# those as we went along.\n",
    "\n",
    "# lets actually now perform face tracking.\n",
    "# To do this, we are gonna perform object detection on the very first frame, to grab the face location\n",
    "# then we actually have detect the face we are gonna treat that as a bunch of pixels that we are meaning to track\n",
    "# and then we apply meanshift tracking on that face.\n",
    "\n",
    "# so we are detecting the face one time at the very beginning and telling the meanshift tracking algorithm to \n",
    "# track that particular set of pixels\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(r\"C:\\Users\\JERRY\\Downloads\\face.xml\")\n",
    "\n",
    "# essentially this returns back those corners\n",
    "face_rects = face_cascade.detectMultiScale(frame)\n",
    "# This essentially returns a list of all the numpy arrays where it is detecting a face.\n",
    "\n",
    "# our intent is to detect only one face , so lets grab/use the first face it detects.\n",
    "\n",
    "\n",
    "# Keep in mind, we are only going to be able to track one single face using this exact code.\n",
    "\n",
    "(face_x,face_y,w,h) = tuple(face_rects[0])   # we are conveting it in to tuple because it is the required form to proceed furhter\n",
    "\n",
    "track_window = (face_x,face_y,w,h) # this is how we can refer to these points as tracking window\n",
    "\n",
    "# the next step is to set up a ROI for tracking...\n",
    "\n",
    "roi = frame[face_y:face_y+h,face_x:face_x+w]\n",
    "\n",
    "# now we are going to use HSV color mapping\n",
    "\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# so now we are gonna find a histogram to back project the target on each frame in order to calculate that ]\n",
    "# meanshift.\n",
    "\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "\n",
    "# now we normalize histogram array values\n",
    "\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# now we are settting up the termination criteria...\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == True:  # if this is true, we are gonna grab the frame and convert it to HSV\n",
    "       \n",
    "        hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Now we need to calculate the back projection based of the ROI hist that we created earlier.\n",
    "        \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        ret,track_window = cv2.meanShift(dst,track_window,term_crit)\n",
    "        \n",
    "        # then we are going to draw a new rectangle on the image based of this new trackin window is updated.\n",
    "        \n",
    "        x,y,w,h  = track_window\n",
    "        img2 = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),5)\n",
    "        \n",
    "        cv2.imshow('img',img2)\n",
    "        \n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the square is staying the same size regardless of the position of your face. we can not resize it using this method. but with CamShift Tracking, we can change the square size accorfing to the postion of our face.\n",
    "\n",
    "\n",
    "Its preety simple to change the above code from meanshift to camshift.\n",
    "\n",
    "we will write and run the code in the new python notebook. we simply just copy and paste code and make the necessary changes in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
