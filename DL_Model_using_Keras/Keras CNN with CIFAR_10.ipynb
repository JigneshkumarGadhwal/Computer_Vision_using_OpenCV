{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This time we are going to work with color images...\n",
    "\n",
    "We will be working with the CIFAR-10 dataset, which is color images of various objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x212bccea780>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a little bit of preprocessing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/x_train.max()\n",
    "\n",
    "x_test = x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape      # we have 50000 images for trainnig , 10000 for testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train  #   The labels are still in their normal integer category form..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert it to one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,10)    # we have 10 categories in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# convolution layer_1:\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
    "# MaxPool layer_1:\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# we will be adding one more convolution layer since the images are a littel complex, little larger than mnist,\n",
    "# plus we have the three color channels...\n",
    "\n",
    "# convolution layer_2:\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
    "# MaxPool layer_1:\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Flatten:\n",
    "model.add(Flatten())\n",
    "\n",
    "#Dense Hidden layer:  # generally the choice for number of neurons is 2 to the power of something ,\n",
    "# some famous choice of researches are 128,256,512,etc...\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "#The last layer_ classifier: output layer\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               205056    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 225,610\n",
      "Trainable params: 225,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5168 - acc: 0.4547\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.1652 - acc: 0.5941\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.0158 - acc: 0.6470\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.9184 - acc: 0.6835\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.8474 - acc: 0.7108\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.7935 - acc: 0.7320\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.7451 - acc: 0.7480\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.7126 - acc: 0.7578\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.6791 - acc: 0.7731\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 48s 968us/step - loss: 0.6561 - acc: 0.7797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212c7402a20>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_cat_train,verbose=1,epochs=10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 539us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1300515442848205, 0.6729]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's perform classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.70      1000\n",
      "          1       0.86      0.77      0.81      1000\n",
      "          2       0.51      0.62      0.56      1000\n",
      "          3       0.52      0.45      0.48      1000\n",
      "          4       0.62      0.66      0.64      1000\n",
      "          5       0.70      0.41      0.52      1000\n",
      "          6       0.64      0.82      0.72      1000\n",
      "          7       0.78      0.68      0.73      1000\n",
      "          8       0.70      0.84      0.77      1000\n",
      "          9       0.74      0.79      0.77      1000\n",
      "\n",
      "avg / total       0.68      0.67      0.67     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving this updated version of the model to our DATA folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\JERRY\\Python_2K24_25\\OpenCV Udemy\\Computer-Vision-with-Python\\DATA\\Updated_Keras CNN with CIFAR_10\")   # and now its saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainning could be very time consuming for this case , depending upon the speed of the computer, so we just simply use the .h5 trainned model that we have in our DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model(r\"C:\\Users\\JERRY\\Python_2K24_25\\OpenCV Udemy\\Computer-Vision-with-Python\\06-Deep-Learning-Computer-Vision\\cifar_10epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 500us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3167052200317384, 0.0999]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1000\n",
      "          1       0.00      0.00      0.00      1000\n",
      "          2       0.00      0.00      0.00      1000\n",
      "          3       0.10      0.99      0.18      1000\n",
      "          4       0.00      0.00      0.00      1000\n",
      "          5       0.00      0.00      0.00      1000\n",
      "          6       0.00      0.00      0.00      1000\n",
      "          7       0.20      0.01      0.02      1000\n",
      "          8       0.06      0.00      0.01      1000\n",
      "          9       0.00      0.00      0.00      1000\n",
      "\n",
      "avg / total       0.04      0.10      0.02     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
