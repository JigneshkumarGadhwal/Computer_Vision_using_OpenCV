{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals of this section:\n",
    "\n",
    "Connnect OpenCV to a WebCam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use OpenCV to open a video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw shapes on video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interact with video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to a Webcam\n",
    "\n",
    "https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html\n",
    "\n",
    "Note: its important to know that when we are reading a video data, its important that we dont have multple notebook and multiple kernels trying to read in from a video stream file... that would start messing up with how OpenCV deals witih camera, because they start conflicting each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So all we need to actually capture a video stream file is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)    # this command is gonna get our default camera...\n",
    "\n",
    "# We actually want some width and height of an actual capture camera... to manipulate the video image...\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # This actually returns a floating point number, eg- 1080.0 , int() we can cast it to int.\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()  # this basically returns back tuple , that is why we are using tuple unpacking.\n",
    "    \n",
    "    # How we can convert a frame in to gray scale...\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('frame',gray)\n",
    "    \n",
    "    # and finally we are gonna wait untill someone hit the esc key...\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # we can use esc also...this time we use any key on the keyboard to esc sequence\n",
    "        break\n",
    "        \n",
    "cap.release()     \n",
    "cv2.destroyAllWindows()   # before destroying we need to make sure that we stop capturing the video,cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ret,frame = cap.read() -- so what this command actually does is, the video we read is just a series of images.\n",
    "                                        and we use lot of the command we used for image file, except just treat them as single frame, and continously update over and over again for every image frame of the video.\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the above code would give the gray frame video stream, for colored version: \n",
    "\n",
    "comment out :      gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    " cv2.imshow('frame',gray)  : instead of passing gray, pass on frame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
